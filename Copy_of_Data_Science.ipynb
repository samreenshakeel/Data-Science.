{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOFWNDGUrycUBGCAfQA5Tmk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samreenshakeel/Data-Science./blob/main/Copy_of_Data_Science.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exploratory Data Analysis:**\n",
        "\n",
        "Exploratory Data Analysis (EDA) is the process of examining and visualizing data to understand its structure, patterns, and anomalies. It helps prepare the data for modeling by revealing insights and guiding further analysis.\n",
        "\n",
        "**Exploratory Data Analysis on Student Dataset:**\n",
        "\n",
        "In this notebook, we perform a simple exploratory data analysis (EDA) on a sample dataset containing information about students, including their names, ages, and marks. The goal is to understand the basic structure and statistics of the data.\n",
        "\n",
        "We will cover the following steps:\n",
        "\n",
        "1-Display the first few rows of the dataset to get an overview.\n",
        "\n",
        "2-Generate summary statistics for numerical columns.\n",
        "\n",
        "3-Count the total number of students.\n",
        "\n",
        "4_Calculate the average age of students.\n",
        "\n",
        "5-Identify the highest marks obtained.\n",
        "\n",
        "6-Count how many students are older than a certain age (e.g., greater than 22).\n",
        "\n",
        "This initial EDA helps us understand the distribution, central tendencies, and patterns within the data before we proceed to more advanced analysis or modeling.\n",
        "\n",
        "**Explanation:**\n",
        "\n",
        "* df.head() shows the first few rows of the dataset.\n",
        "\n",
        "* df.describe() gives summary statistics like mean, std, min, max, etc.\n",
        "\n",
        "* df['Name'].count() counts the number of students.\n",
        "\n",
        "* df['Age'].mean() finds the average age of students.\n",
        "\n",
        "* f['Marks'].max() finds the highest marks obtained by a student.\n",
        "\n",
        "* df[df['Age'] > 22] filters students older than 22.\n"
      ],
      "metadata": {
        "id": "2P1VcDWs9dTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame with students' data\n",
        "data = {\n",
        "    'Name': ['Iqra', 'Sara', 'Eman', 'Saba', 'Noor'],\n",
        "    'Age': [23, 25, 22, 24, 21],\n",
        "    'Marks': [88, 92, 85, 90, 87]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# 1. Checking the first few rows of the dataset\n",
        "print(\"First 5 rows:\")\n",
        "print(df.head())\n",
        "\n",
        "# 2. Summary statistics for numerical columns\n",
        "print(\"\\nSummary statistics:\")\n",
        "print(df.describe())\n",
        "\n",
        "# 3. Count of students\n",
        "print(\"\\nNumber of students:\")\n",
        "print(df['Name'].count())\n",
        "\n",
        "# 4. Average age of students\n",
        "print(\"\\nAverage age of students:\")\n",
        "print(df['Age'].mean())\n",
        "\n",
        "# 5. Highest marks obtained\n",
        "print(\"\\nHighest marks:\")\n",
        "print(df['Marks'].max())\n",
        "\n",
        "# 6. Count of students above a certain age (e.g., age > 22)\n",
        "print(\"\\nStudents older than 22:\")\n",
        "print(df[df['Age'] > 22].count())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGdhsB4S2aOn",
        "outputId": "35e1c127-b385-4297-dbff-02d6a39e354a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows:\n",
            "   Name  Age  Marks\n",
            "0  Iqra   23     88\n",
            "1  Sara   25     92\n",
            "2  Eman   22     85\n",
            "3  Saba   24     90\n",
            "4  Noor   21     87\n",
            "\n",
            "Summary statistics:\n",
            "             Age      Marks\n",
            "count   5.000000   5.000000\n",
            "mean   23.000000  88.400000\n",
            "std     1.581139   2.701851\n",
            "min    21.000000  85.000000\n",
            "25%    22.000000  87.000000\n",
            "50%    23.000000  88.000000\n",
            "75%    24.000000  90.000000\n",
            "max    25.000000  92.000000\n",
            "\n",
            "Number of students:\n",
            "5\n",
            "\n",
            "Average age of students:\n",
            "23.0\n",
            "\n",
            "Highest marks:\n",
            "92\n",
            "\n",
            "Students older than 22:\n",
            "Name     3\n",
            "Age      3\n",
            "Marks    3\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Handling Missing Values:**\n",
        "Real-world datasets often contain missing or incomplete data, which can affect the accuracy and performance of data analysis and machine learning models.\n",
        "\n",
        "**Handling Missing Values in a Dataset**\n",
        "\n",
        "In this notebook, we demonstrate how to detect and handle missing values using a sample dataset of student information.\n",
        "\n",
        "We will perform the following steps:\n",
        "\n",
        "Display the first few rows of the dataset to understand its structure.\n",
        "\n",
        "1-Identify the missing values in each column.\n",
        "\n",
        "2-Fill the missing values in the 'Age' column using the mean age.\n",
        "\n",
        "3-Fill the missing values in the 'Marks' column using the median marks.\n",
        "\n",
        "4-Verify that all missing values have been properly handled.\n",
        "\n",
        "This basic preprocessing step ensures that the dataset is clean and ready for further analysis or modeling.\n",
        "\n",
        "**Explanation:**\n",
        "\n",
        "* df.isnull().sum() shows how many missing values there are in each column.\n",
        "\n",
        "* df['Age'].fillna(df['Age'].mean()) fills missing values in the \"Age\" column with the mean of the available ages.\n",
        "\n",
        "* df['Marks'].fillna(df['Marks'].median()) fills missing values in the \"Marks\" column with the median of the available marks.\n",
        "\n",
        "* After filling, we check if there are still missing values with df.isnull().sum().\n",
        "\n",
        "This code is useful for basic imputation of missing values and ensures that the dataset is complete for analysis.\n",
        "\n"
      ],
      "metadata": {
        "id": "moniI0173C9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Sample DataFrame with missing values\n",
        "data = {\n",
        "    'Name': ['Iqra', 'Sara', 'Eman', 'Saba', 'Noor'],\n",
        "    'Age': [23, np.nan, 22, 24, np.nan],\n",
        "    'Marks': [88, 92, np.nan, 90, 87]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# 1. Checking the first few rows of the dataset\n",
        "print(\"First 5 rows:\")\n",
        "print(df.head())\n",
        "\n",
        "# 2. Checking for missing values\n",
        "print(\"\\nMissing values in each column:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# 3. Fill missing values in 'Age' with the mean age\n",
        "df['Age'] = df['Age'].fillna(df['Age'].mean())\n",
        "\n",
        "# 4. Fill missing values in 'Marks' with the median marks\n",
        "df['Marks'] = df['Marks'].fillna(df['Marks'].median())\n",
        "\n",
        "# 5. Checking if there are any missing values after filling\n",
        "print(\"\\nMissing values after filling:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# 6. Counting students with missing marks before filling\n",
        "missing_marks_count = df['Marks'].isnull().sum()\n",
        "print(f\"\\nNumber of students with missing marks before filling: {missing_marks_count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18nOyTHR4BgT",
        "outputId": "d683750b-0f00-4ed8-d4e7-0f01b8ebea3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows:\n",
            "   Name   Age  Marks\n",
            "0  Iqra  23.0   88.0\n",
            "1  Sara   NaN   92.0\n",
            "2  Eman  22.0    NaN\n",
            "3  Saba  24.0   90.0\n",
            "4  Noor   NaN   87.0\n",
            "\n",
            "Missing values in each column:\n",
            "Name     0\n",
            "Age      2\n",
            "Marks    1\n",
            "dtype: int64\n",
            "\n",
            "Missing values after filling:\n",
            "Name     0\n",
            "Age      0\n",
            "Marks    0\n",
            "dtype: int64\n",
            "\n",
            "Number of students with missing marks before filling: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Handling Outliers:**\n",
        "\n",
        "Outliers are data points that significantly differ from other observations in a dataset. They can distort statistical analyses and negatively impact the performance of machine learning models. Detecting and removing outliers is an important part of data cleaning and preprocessing.\n",
        "\n",
        "**Handling Outliers in a Dataset:**\n",
        "\n",
        "In this notebook, we use a sample dataset containing student information with some extreme values in the 'Age' and 'Marks' columns.\n",
        "\n",
        "We will perform the following steps:\n",
        "\n",
        "1-dentify outliers in the 'Age' column using the Interquartile Range (IQR) method.\n",
        "\n",
        "2-Remove the detected outliers from the dataset.\n",
        "\n",
        "3-Repeat the same process to detect and remove outliers in the 'Marks' column.\n",
        "\n",
        "4-Display the cleaned dataset after outlier removal.\n",
        "\n",
        "Using the IQR method helps us retain most of the data while filtering out values that fall too far outside the normal range.\n",
        "\n",
        " **Explanation:**\n",
        "\n",
        "* Detects outliers in \"Age\" and \"Marks\" using the IQR (Interquartile Range) method.\n",
        "\n",
        "* Removes rows with outlier values.\n",
        "\n",
        "* Prints the cleaned dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "LfIJEVhe4F90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame with some outliers\n",
        "data = {\n",
        "    'Name': ['Iqra', 'Sara', 'Eman', 'Saba', 'Noor', 'Hajra'],\n",
        "    'Age': [23, 25, 100, 24, 22, 21],   # 100 is an outlier\n",
        "    'Marks': [88, 92, 85, 300, 87, 89]  # 300 is an outlier\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# 1. Detecting outliers in 'Age' using IQR method\n",
        "Q1_age = df['Age'].quantile(0.25)\n",
        "Q3_age = df['Age'].quantile(0.75)\n",
        "IQR_age = Q3_age - Q1_age\n",
        "\n",
        "# 2. Filtering out the outliers in Age\n",
        "df = df[(df['Age'] >= Q1_age - 1.5 * IQR_age) & (df['Age'] <= Q3_age + 1.5 * IQR_age)]\n",
        "\n",
        "# 3. Detecting and removing outliers in 'Marks'\n",
        "Q1_marks = df['Marks'].quantile(0.25)\n",
        "Q3_marks = df['Marks'].quantile(0.75)\n",
        "IQR_marks = Q3_marks - Q1_marks\n",
        "\n",
        "df = df[(df['Marks'] >= Q1_marks - 1.5 * IQR_marks) & (df['Marks'] <= Q3_marks + 1.5 * IQR_marks)]\n",
        "\n",
        "# 4. Final clean data after removing outliers\n",
        "print(\"Data after removing outliers:\")\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5XLIDZt5TWm",
        "outputId": "ded30cf9-edd6-411a-8f2b-b4b58494d539"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data after removing outliers:\n",
            "    Name  Age  Marks\n",
            "0   Iqra   23     88\n",
            "1   Sara   25     92\n",
            "4   Noor   22     87\n",
            "5  Hajra   21     89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Categorical Encoding:**\n",
        "\n",
        "Categorical data refers to variables that contain label values rather than numeric values. Machine learning models usually require all input features to be numeric, so converting categorical data into a numerical format is an essential preprocessing step.\n",
        "\n",
        "**Categorical Encoding in a Dataset:**\n",
        "\n",
        "In this notebook, we work with a sample dataset that includes a categorical column: 'Gender'. We demonstrate two popular encoding techniques:\n",
        "\n",
        "**Label Encoding:** Converts categories into numeric labels (e.g., Male = 1, Female = 0). This method is simple but may introduce unintended ordinal relationships.\n",
        "\n",
        "**One-Hot Encoding:** Creates separate binary columns for each category, avoiding any implied order between them. This is the preferred method for nominal (unordered) categorical data.\n",
        "\n",
        "These encoding methods prepare categorical variables for use in machine learning algorithms.\n",
        "\n",
        "**Explanation:**\n",
        "\n",
        "* map() is used for simple label encoding.\n",
        "\n",
        "* pd.get_dummies() is used for one-hot encoding, which turns the \"Gender\" column into \"Gender_Female\" and \"Gender_Male\".\n",
        "\n",
        "* You can apply the same method to other categorical columns like \"Grade\", \"Subject\", etc\n",
        "\n"
      ],
      "metadata": {
        "id": "7tYqp29q5vgW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample data with a categorical column\n",
        "data = {\n",
        "    'Name': ['Iqra', 'Sara', 'Eman', 'Saba', 'Noor'],\n",
        "    'Gender': ['Female', 'Male', 'Male', 'Male', 'Female'],  # Categorical\n",
        "    'Age': [23, 25, 22, 24, 21],\n",
        "    'Marks': [88, 92, 85, 90, 87]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# 1. Label Encoding for 'Gender' (Male = 1, Female = 0)\n",
        "df['Gender_Label'] = df['Gender'].map({'Male': 1, 'Female': 0})\n",
        "\n",
        "# 2. One-Hot Encoding for 'Gender'\n",
        "df_onehot = pd.get_dummies(df, columns=['Gender'])\n",
        "\n",
        "# 3. Show original with label and one-hot encoding\n",
        "print(\"Data with Label Encoding:\")\n",
        "print(df[['Name', 'Gender', 'Gender_Label']])\n",
        "\n",
        "print(\"\\nData with One-Hot Encoding:\")\n",
        "print(df_onehot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ov3Pnp151Tz",
        "outputId": "090605a5-bc03-47d1-84ef-137df400466a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data with Label Encoding:\n",
            "   Name  Gender  Gender_Label\n",
            "0  Iqra  Female             0\n",
            "1  Sara    Male             1\n",
            "2  Eman    Male             1\n",
            "3  Saba    Male             1\n",
            "4  Noor  Female             0\n",
            "\n",
            "Data with One-Hot Encoding:\n",
            "   Name  Age  Marks  Gender_Label  Gender_Female  Gender_Male\n",
            "0  Iqra   23     88             0           True        False\n",
            "1  Sara   25     92             1          False         True\n",
            "2  Eman   22     85             1          False         True\n",
            "3  Saba   24     90             1          False         True\n",
            "4  Noor   21     87             0           True        False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Normalization and Standardization:**\n",
        "\n",
        "When working with numerical data, it's important to scale the values so that they are on a similar range. This is especially critical for many machine learning algorithms that are sensitive to the scale of input features.\n",
        "\n",
        "**Normalization and Standardization of Data:**\n",
        "\n",
        "In this notebook, we demonstrate two common data scaling techniques:\n",
        "\n",
        "**Normalization:** Also known as Min-Max Scaling, this technique rescales the data to a fixed range, usually 0 to 1. It is useful when the data needs to be bounded and evenly scaled.\n",
        "\n",
        "**Standardization:** This technique transforms the data to have a mean of 0 and a standard deviation of 1. It is useful when the data follows a normal distribution or when algorithms assume a Gaussian distribution (e.g., logistic regression, SVM).\n",
        "\n",
        "We apply both methods to the 'Age' and 'Marks' columns in a sample dataset to compare the results. These techniques ensure that features contribute equally to the model performance and improve convergence speed in training.\n",
        "\n",
        "**Explanation:**\n",
        "\n",
        "* MinMaxScaler transforms data between 0 and 1 (Normalization).\n",
        "\n",
        "* StandardScaler transforms data to have mean 0 and standard deviation 1 (Standardization).\n",
        "\n",
        "We apply both on the numeric columns Age and Marks.\n"
      ],
      "metadata": {
        "id": "cYK0hIwn542D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "# Sample data\n",
        "data = {\n",
        "    'Name': ['Iqra', 'Sara', 'Eman', 'Saba', 'Noor'],\n",
        "    'Age': [23, 25, 22, 24, 21],\n",
        "    'Marks': [88, 92, 85, 90, 87]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# 1. Normalization (scales data between 0 and 1)\n",
        "scaler_norm = MinMaxScaler()\n",
        "df[['Age_Norm', 'Marks_Norm']] = scaler_norm.fit_transform(df[['Age', 'Marks']])\n",
        "\n",
        "# 2. Standardization (mean = 0, std = 1)\n",
        "scaler_std = StandardScaler()\n",
        "df[['Age_Std', 'Marks_Std']] = scaler_std.fit_transform(df[['Age', 'Marks']])\n",
        "\n",
        "# 3. Show the result\n",
        "print(\"Data with Normalization and Standardization:\")\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSSMQ2-s6jrO",
        "outputId": "fe95f276-9962-4e19-f243-757191f0c913"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data with Normalization and Standardization:\n",
            "   Name  Age  Marks  Age_Norm  Marks_Norm   Age_Std  Marks_Std\n",
            "0  Iqra   23     88      0.50    0.428571  0.000000  -0.165521\n",
            "1  Sara   25     92      1.00    1.000000  1.414214   1.489691\n",
            "2  Eman   22     85      0.25    0.000000 -0.707107  -1.406930\n",
            "3  Saba   24     90      0.75    0.714286  0.707107   0.662085\n",
            "4  Noor   21     87      0.00    0.285714 -1.414214  -0.579324\n"
          ]
        }
      ]
    }
  ]
}